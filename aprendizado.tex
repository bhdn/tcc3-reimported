% 
% Aprendizado de máquina
%

\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\norma}[1]{\lVert #1 \rVert}

% Usar Inductive Principles for Learning from Data como referência "dos
% tópicos" para esse assunto, e também o "Uma Introdução às Support Vector
% Machines".
% Tomar cuidado em manter a consistência entre as diferentes notações
% usadas entre as referências.
%
% - A teoria do aprendizado estatístico
% - Métodos paramétricos
% - Métodos adaptativos
% - Risco esperado, risco estatístico
% - Classificação binária
% - Classificação multi-classes
% - Como adaptar um classificador binário para um problema multi-classes
%   (Pairwise, e esqueciooutro)
%
% Apresentar (brevemente) algumas outras técnicas também:
% (lista baseada em wiki/Supervised_learning#Approaches_and_algorithms)
% - redes neurais artificiais
% - inferência bayesiana
% - ...
%
% FIXME Aqui realmente estou em dúvida. Devemos apresentar TODAS as
% técnicas, uma por parágrafo, ou apresentar uma a uma?
% -- Pelo que tenho visto em outras monografias, não é necessário
%  apresentar o estado da arte da área de aprendizado (Ver Trabalhos
%  Relacionados no Google Docs)

Um dos comportamentos mais característicos de sistemas computacionais que possam ser considerados inteligentes é o de melhorar o seu desempenho para resolver algum problema quando este se depara com a mesma situação por mais de uma vez ~\cite{luger2004inteligencia}. ~\apudonline{simon1983should}{luger2004inteligencia} define o conceito de aprendizado de máquina como sendo qualquer mudança que melhore o seu desempenho na segunda vez que ele repetir a mesma tarefa, ou numa tarefa da mesma população.

Nem sempre é possível obter um resultado ótimo para novas situações, pois na maioria dos casos não é possível apresentar a um sistema a quantidade de exemplos (ou experiências anteriores) necessárias para representar todos os casos possíveis. Por isso, as técnicas de aprendizado fazem uso da inferência indutiva, que consiste em prever novas situações baseando-se em um conjunto particular de exemplos~\cite{luger2004inteligencia}.

A construção da hipótese no aprendizado indutivo ocorre por meio da exposição de exemplos ao algoritmo de indução, e este processo é chamado de treinamento. O processo de atribuir rótulos ou classes a novos exemplos é chamado de classificação.

Porém, se o conjunto de exemplos usado para a indução for muito pequeno ou pouco representativo, há o risco de que as hipóteses escolhidas não descrevam corretamente novas situações e o sistema inteligente traga resultados incorretos~\cite[p. 90]{rezende2003sistemas}.

Sistemas de aprendizado de máquina podem ser divididos em dois tipos de acordo com a maneira que é feito o treinamento: supervisionados e não-supervisionados.

O aprendizado supervisionado é aquele em que há exemplos pré-existentes e estes já possuem rótulos. Estes rótulos podem ter sido atribuídos por um especialista no domínio ou representam resultados de experiências anteriores do sistema. Um classificador baseado em aprendizado supervisionado deve tentar estabelecer uma hipótese que seja genérica a ponto de que o algoritmo possa classificar corretamente novos casos. Uma hipótese muito genérica pode resultar em uma classificação inadequada (\emph{underfitting} --- sub-ajuste), ao passo que uma hipótese que descreva corretamente apenas os exemplos que foram usados para o treinamento pode ter um desempenho inadequado em casos novos (\emph{overfitting} --- sobre-ajuste).

No aprendizado não-supervisionado, não há rótulos para atribuir aos exemplos, pois o objetivo do algoritmo é encontrar grupos de exemplos que possuam semelhança entre eles. As técnicas deste modelo são referenciadas como sendo ``técnicas de agrupamento'' ou \emph{clustering}~\cite{rezende2003sistemas}.
%FIXME terminar não-supervisionado (dar uma olhada no livro do Luger)

\subsection{Técnicas de aprendizado supervisionado}

Dentre as técnicas de aprendizado supervisionado mais populares estão Redes Neurais, Máquinas de Vetores de Suporte (\emph{Support Vector Machines} --- SVMs), $k$ Vizinhos Mais Próximos ($k$-NN) e \emph{Naïve Bayes}.

% FIXME faltou descrever GGM, RBF, Redes Bayesianas e árvores de decisão

$k$-NN (de \emph{k-Nearest Neighbors}, $k$-Vizinhos Mais Próximos) é uma técnica de aprendizado supervisionado que utiliza todos os exemplos durante a etapa de classificação, tendo assim pouco custo para treinamento e alto custo para classificação. Para classificar as entradas, comumente mede-se a distância euclideana de todos os exemplos da base e então é selecionada a classe que predomina no grupo de $N$ elementos que estiver mais próximo\cite{tan2006effective}.

Há também as técnicas baseadas em Árvores de Decisão, que visam a indução de uma árvore que represente o conhecimento. Os ramos desta árvore indicam conjunções (tanto de testes binários quanto multivalorados), ao passo que as folhas representam classficações. Para classificar novos casos simplemente percorre-se a árvore de decisão avaliando cada conjunção em cada ramo e seguindo para a subárvore adequada, quando atinge-se as folhas é encontrada a classe final~\cite{de-categorizacao}. Esta técnica possui a vantagem de que sua forma de representação permita que humanos compreendam com facilidade o conteúdo que ela representa~\cite[p. 52]{mitchell1997machine}. Os algoritmos para indução de árvores de decisão mais populares são ID3~\cite{quinlan1986induction}, C4.5~\cite{quinlan1993programs} e CART~\cite{breiman1984classification}.

\emph{Naïve Bayes} é um algoritmo de aprendizado supervisionado, que
utiliza probabilidade para a classificação e supõe que as variáveis de cada
exemplo são condicionalmente independentes \cite{de-categorizacao}, as
probabilidades são calculadas de acordo com o Teorema de Bayes
\cite{kim2003poisson}, para a classificação de um elemento desconhecido, é
calculada a probabilidade de todas as classes e a classe com maior
probabilidade é escolhida como rótulo para o elemento desconhecido.
~\cite{pardo2002aprendizado}

As Redes Neurais Artificiais (RNAs) são modelos matemáticos baseados no neurônio biológico, têm a capacidade computacional adquirida por meio de aprendizado e generalização, são capazes de resolver problemas de aproximação, predição, classificação e otimização. A aprendizagem de uma rede neural ocorre a partir dos exemplos e tende a melhorar seu desempenho conforme a qualidade dos exemplos, já a generalização surge como consequência do aprendizado. O processamento das informações pode ser feito de forma paralela e distribuída, através dos neurônios da rede neural artificial, onde cada neurônio é um elemento processador.~\cite{rezende2003sistemas}

\emph{Support Vector Machines} é uma técnica modelada como um problema de otimização que tenta encontrar, no espaço do conjunto de exemplos, um hiperplano que separe com maior margem os exemplos de cada uma das duas classes. Em razão da aplicação desta técnica em parte da metodologia proposta neste trabalho, será feita uma apresentação mais detalhada a partir da seção \ref{sec:svm}) (página \pageref{sec:svm}). Antes disso, as seções a seguir buscam apresentar os conceitos e terminologia comumente utilizados na apresentação das SVMs.

\subsection{Formalização do aprendizado supervisionado}

Como já brevemente apresentado, no problema de aprendizado supervisionado existe a figura de um professor que indica qual é o rótulo correto para cada exemplo \apud{haykin1994neural}{lorena2003introducaoas}. Sendo assim, cada exemplo pode ser descrito na forma $(\vect{x}_i, y_i)$, aonde $\vect{x}_i$ denota um exemplo e $y_i$ seria a classe ou rótulo. Também, após o processo de treinamento, pode-se descrever o classificador como uma função $f(\vect{x}) = y$, sendo que $\vect{x}$ não é necessariamente um dos valores de $\vect{x}_i$.

Os valores dos rótulos que os exemplos podem assumir podem ser discretos ou contínuos. Para o caso dos contínuos assume-se que é possível obter $1,\dotsc,k$ valores. Quando $k = 2$, o problema é denominado como sendo de ``classificação binária''. Quando $k > 2$ denomina-se como sendo um problemas de ``classificação multiclasses''.

Os exemplos $\vect{x}_i$, são representados por vetores com as características (também denominadas atributos) de cada exemplo. Cada exemplo $\vect{x}_i$ possui $m$ atributos e também pode ser representado como $\vect{x}_i = (x_{i1},\dotsc,x_{im})$. Os atributos podem assumir dois tipos de valores: nominais ou contínuos. Os atributos nominais assumem valores que não possuem ordem entre si e sua representação tem função simbólica (por exemplo: segunda-feira, azul, não). Os atributos contínuos possuem ordem entre si e comumente representam valores dos domínios $\mathbb{Z}$ e $\mathbb{R}$.

O objetivo de uma técnica de aprendizado de máquina é obter uma função $f(\vect{x}) = y$ que obtenha um $y$ adequado aos exemplos que foram apresentados pelo professor por meio de indução~\cite{osuna1997support}.

% parece ser muito pouco conteúdo, porém mais detalhes como (overfitting) ou
% (como avaliar o desempenho de alguma técnica de AM) já foram (acima) ou serão
% (em classificação de textos).

\subsection{Support Vector Machines --- \it{SVMs}}\label{sec:svm}
%
%   - problema primal
%   - problema dual (e teoria "dos lagrangianos")
%   - vetores de suporte
%   - SVM com margens rígidas
%   - SVM com margens flexíveis (E_i)
%   - kernels (RBF gaussiano etc)

A técnica de aprendizado de máquina supervisionado conhecida como \emph{Support Vector Machine} (SVM) ou Máquinas de Vetores de Suporte, foi introduzida por Boser, Guyon e Vapnik em 1992 com a publica\c{c}ão de \emph{A training algorithm for optimal margin classifiers}\nocite{boser1992training}. Esta baseia-se no trabalho da teoria do aprendizado estatístico desenvolvida por Vapnik et al. desde a década de 1960~\cite{antos2003data}.

SVMs usam o princípio de que quanto mais largas as margens de um hiperplano separador de uma fun\c{c}ão, que foi explicado na se\c{c}ão \ref{sec:aprendizado} por meio do conceito de minimiza\c{c}ão do risco estrutural, maiores são as chances de que ele possa prover uma boa generaliza\c{c}ão dos dados que estão sendo usados como exemplo \cite{chapelle2002choosing}. Então, SVMs buscam encontrar um hiperplano descrito por $f(\vect{x}) = \vect{w}\cdot\vect{x} + b = 0$ que tenha maior margem entre as classes e menor complexidade estrutural por meio da resolu\c{c}ão de um problema de otimiza\c{c}ão.

Para encontrar o hiperplano separador ideal, é necessário utilizar (pelo menos) dois pontos do conjunto de exemplos. Sejam $\vect{x}_1$ e $\vect{x}_2$ dois exemplos do conjunto de treinamento $T$ que possui um conjunto de exemplos $X$ com rótulos do conjunto de exemplos $Y = \{-1, +1\}$, e cada um deles fica em um lado diferente do hiperplano separador. Para encontrar o hiperplano separador $f(\vect{x}) = \vect{w}\cdot\vect{x} + b = 0$ entre $\vect{x}_1$ e $\vect{x}_2$, é necessário conhecer o vetor $\vect{w}$, que deve ser normal a este hiperplano e que é usado para calcular o tamanho da margem.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{img/fig-hiperplanos.png}
  \figinfox{Hiperplano separador e margens}{LORENA, 2003}
  \label{fig:hiperplanos}
\end{figure}

Como um dos objetivos do problema de otimização é obter uma margem larga entre os exemplos, pode-se restringir a busca por $\vect{w}$ apenas em termos do cálculo do tamanho da margem. Para isso, é necessário calcular a distância entre dois hiperplanos que são formados pelos exemplos $\vect{x}_1$ e $\vect{x}_2$. Sejam $H_1: \vect{w}\cdot\vect{x} + b = +1$ e $H2: \vect{w}\cdot\vect{x} +b = -1$ dois hiperplanos que ficam paralelamente acima e abaixo, respectivamente, do hiperplano separador. Além disso, assume-se que $H_1$ passa por $\vect{x}_1$ e $H_2$ passa por $\vect{x}_2$. A figura \ref{fig:hiperplanos} mostra a relação entre os hiperplanos e os pontos $\vect{x}_1$ e $\vect{x}_2$.

Conhecendo os hiperplanos, agora é possível calcular a distância entre os hiperplanos que servem de fronteira entre cada ponta da margem do hiperplano separador. A equação \ref{eq:projecao_w} apresenta o cálculo necessário para projetar $\vect{x}_1 - \vect{x}_2$ na direção de $\vect{w}$, que é perpendicular ao hiperplano separador $\vect{w}\cdot\vect{x} + b = 0$.
\begin{equation}\label{eq:projecao_w}
  (x_1 - x_2)
    \left(
      \frac{ \vect{w} }{ \norma{\vect{w}} }
      \cdot
      \frac{(x_1 - x_2)}{ \norma{\vect{x}_1 - \vect{x}_2} }
    \right)
\end{equation}

Sabendo que $\vect{w}\cdot\vect{x}_1 + b = +1$ e $\vect{w}\cdot\vect{x}_2 + b = -1$, e levando em conta que deseja-se saber o comprimento do vetor resultante, é usada a norma da equação \ref{eq:projecao_w} para chegar à equação \ref{eq:projecao_w2}, que indica a distância $d$ utilizada na figura \ref{fig:hiperplanos}:
\begin{equation}\label{eq:projecao_w2}
  d = \frac{2}{\norma{\vect{w}}}
\end{equation}

Portanto, as distâncias entre $\vect{x}_1$, $\vect{x}_2$ e o hiperplano separador $\vect{w}\cdot\vect{x} + b = 0$ são $\frac{1}{\norma{\vect{w}}}$, e com isso, é possível definir o problema de otimização como definido pelo problema de otimização \ref{eq:max_w0}. A restrição \ref{eq:max_w1} indica que $H_1$ e $H_2$ devem passar, respectivamente, pelos vetores $\vect{x}_1$ e $\vect{x}_2$.
\begin{eqnarray}
& \label{eq:max_w0}\operatorname{Maximizar} & \frac{2}{\norma{\vect{w}}} \\
& \label{eq:max_w1} \operatorname{sujeito\;a} & y_i(\vect{w}\cdot\vect{x}_i + b) - 1 \ge 0 \quad i = 1,\dotsc,n.
\end{eqnarray}

No problema de maximização \ref{eq:max_w0}, $\frac{2}{\norma{\vect{w}}}$ pode também ser descrito como um problema de minimização de $\norma{\vect{w}}^2/{2}$:
\begin{eqnarray}
& \label{eq:min_w0}\operatorname{Minimizar} & \frac{\norma{\vect{w}}^2}{2} \\
& \nonumber \operatorname{sujeito\;a} & y_i(\vect{w}\cdot\vect{x}_i + b) - 1 \ge 0 \quad i = 1,\dotsc,n.
\end{eqnarray}

A partir deste ponto, o problema \ref{eq:min_w0} pode ser resolvido com técnicas de programação quadrática (PQ) \cite{osuna1997support}. Este tipo de problema pode ser solucionado utilizando uma função Lagrangiana e adicionando as restrições à função objetivo junto com os multiplicadores de Lagrange $\alpha_i$ \cite{smola2000advances}. A equação \ref{eq:lagrange0} deve ser minimizada, o que significa maximizar $\alpha_i$ e minimizar $\vect{w}$ e $b$. O problema é representado desta forma para que a restrição \ref{eq:max_w1} possa ser representada na forma dos multiplicadores $\alpha_i$, o que facilita os cálculos mais adiante, e também porque os dados de treinamento apenas aparecem na forma de produtos entre vetores \cite{burges1998tutorial}, o que permite o uso de \emph{kernels}, que são apresentados na seção \ref{sec:naolinear}.
\begin{equation}\label{eq:lagrange0}
  L(\vect{w}, b, \vect{\alpha}) = \frac{1}{2}\norma{\vect{w}}^2 - 
       \sum_{i=1}^n{\alpha_i(y_i(\vect{w}\cdot\vect{x}_i + b) - 1)}
\end{equation}

% TODO REV (pg16) "escrever um parágrafo definindo o polinômio de lagrange"

Tem-se ponto de sela, então:
\begin{eqnarray}\label{eq:sela}
  \frac{\partial{L}}{\partial{b}} = 0 & \text{e} & \frac{\partial{L}}{\partial{\vect{w}}} = 0
\end{eqnarray}
E com isso:
\begin{eqnarray}
&  \label{eq:lagsum0}  \sum_{i=1}^n{\alpha_i y_i} = 0 \\
&  \label{eq:lagsum1}  \vect{w} = \sum_{i=1}^n{\alpha_i y_i\vect{x}_i}
\end{eqnarray}

Assim, substituindo equações \ref{eq:lagsum0} e \ref{eq:lagsum1}, é possível formular o problema de otimização:
\begin{eqnarray}\label{eq:maxalpha}
\begin{array}{rl}
   %\operatorname*{Maximizar}_{\alpha}
   \underset{\alpha}{\operatorname{Maximizar}}
   & \sum_{i=1}^n{\alpha_i - \frac{1}{2}}
                            \sum_{i,j=1}^n{\alpha_i\alpha_j y_i y_j(\vect{x}_i\cdot\vect{x}_j)} \\
\operatorname{sujeito\;a} &
  \begin{cases}
    \alpha_i \geqslant 0, \forall{i} = 1,\dotsc,n \\
    \sum_{i=1}^n{\alpha_i y_i} = 0
  \end{cases}
\end{array}
\end{eqnarray}

A equação \ref{eq:maxalpha} é denominada a forma dual do problema, ao passo que a formulação original na equação \ref{eq:min_w0} é denominada a forma primal, baseada no trabalho de \apudonline{fletcher1987practical}{burges1998tutorial}.

% TODO REV Marcio pg16, "o que é forma primal e forma dual?"
% TODO REV Marcio pg16, "quais são as condições [de KKT]"

É possível utilizar as condições KKT (de Karush-Kuhn-Tucker), descritas em \citeonline[proposição 3.3.1]{bertsekas-nonlinear}, visto que o problema de otimização \ref{eq:maxalpha} possui restrições lineares e a função objetivo é convexa \cite{burges1998tutorial}. Assim, segundo essas condições, é possível encontrar $\vect{w^*}$ e $b^*$ que podem ser considerados solução ótima para o problema a partir da solução do problema dual ao encontrar $\alpha_i^*$:
\begin{equation}\label{eq:dualalpha}
  \alpha_i^*(y_i(\vect{w^*}\cdot\vect{x}_i+b^*) - 1) = 0, \forall{i}=1,\dotsc,n
\end{equation}

Nesta equação $\alpha_i^*$ é diferente de zero apenas para os valores que tocam a borda das margens do hiperplano de decisão ($H_1$ e $H_2$). Assim, esses dados são chamados de ``vetores de suporte'', pois são os dados mais significativos para a localização de hiperplano $\vect{w}\cdot\vect{x} + b = 0$.

E para calcular $b^*$, de acordo com \ref{eq:dualalpha}:
\begin{equation}\nonumber
  b^* = \frac{1}{n_{SV}}\sum_{x_j \in SV}{\frac{1}{y_j} - \vect{w^*}\cdot\vect{x}_j}
\end{equation}

Aonde $n_{SV}$ é o número de vetores de suporte e $SV$ o conjunto dos mesmos.

% ALELUIA!!!!!!!!!!!! PQPQPQPQPQPQPQP!!!
Finalmente, obtém-se a seguinte função classificadora:
\begin{equation}\label{eq:classificadora}
  g(\vect{x}) = \operatorname{sinal}(f(\vect{x}))
              = \operatorname{sinal}\left(
                  \sum_{x_i \in SV}{y_i\alpha_i^*\vect{x}_i\cdot\vect{x}+b^*}
                \right)
\end{equation}

\subsubsection{Margens suaves}

% seção está incompleta, não explica bem como o erro é tratado em si

Para tratar os casos em que há \emph{outliers} nos exemplos, ou seja, dados que estão rotulados incorretamente ou com algum ruído, utiliza-se a técnica de margens suaves, que é uma saída mais simples que SVMs não-lineares \cite{burges1998tutorial}.

Utiliza-se variáveis de folga $\xi_i$ para cada exemplo $\vect{x}_i$ do conjunto de treinamento. Essas variáveis são adicionadas à restrição do problema primal:
\begin{equation}\label{eq:restrsuave}
  y_i(\vect{w}\cdot\vect{x}_i+b) \geqslant 1 - \xi_i,\quad\forall{i}=1,\dotsc,n
\end{equation}

Ao passo que a função objetivo é reformulada como:
\begin{equation}
  \underset{\vect{w}, b, \vect{\xi}}{\operatorname{Minimizar}}\quad
         \frac{1}{2}\norma{\vect{w}}^2+C\left(\sum_{i=1}^n{\xi_i}\right)
\end{equation}

A constante $C$ impõe uma penalização à violação das restrições \ref{eq:restrsuave} do problema de otimização. O valor desta constante é definida pelo usuário e sua definição depende de testes baseados no conjunto de treinamento. Algumas abordagens para a escolha deste parâmetro foram apresentadas por \citeonline{chapelle2002choosing}, \citeonline{cherkassky2004practical}, \citeonline{quang2002evolving} e \cite{ben2010user}.

% FIXME descrever o método de busca em grade de ben2010user, pois é o que
% usamos

\subsubsection{Classificação não-linear}\label{sec:naolinear}

Segundo o teorema de \citeonline{cover1965geometrical}, as chances de que um conjunto de exemplos não linearmente separável possa ser separado por um hiperplano é grande quando este é disposto em um espaço de maior dimensionalidade. Assim, a implementação das máquinas de vetores de suporte utiliza esta técnica para conseguir separar dados ainda de maneira linear~\cite{burges1998tutorial}.

Com isso, os dois vetores $\vect{x}$ e $\vect{x}_i$, que são utilizados na função de decisão \ref{eq:classificadora}, são convertidos para o espaço de maior dimensão por um mapeamento $\vect{\Phi}: X \rightarrow \Im$, aonde $X$ é o espaço de entrada e $\Im$ o espaço de características.

Adicionalmente, o produto entre os vetores $\vect{x}$ e $\vect{x}_i$ é representado como uma função $K(\vect{x}_i, \vect{x}_j) = \vect{\Phi}(\vect{x}_i)\cdot\vect{\Phi}(\vect{x}_j)$. Esta função é chamada de \emph{função kernel} e tem por finalidade permitir o uso de funções que atentem às condições definidas pelo teorema de Mercer \cite[p. 141]{burges1998tutorial}. Esta forma de representação permite que se use estas funções de kernel dentro da implementação de uma SVM sem a necessidade de conhecimento dos detalhes internos das mesmas. O quadro \ref{quadro:kernels} apresenta alguns dos kernels mais populares utilizados com SVMs~\cite{lorena2003introducaoas}.

\begin{table}
\centering
\begin{tabular}{|c|c|c|}
\hline
Tipo de kernel & Função & Parâmetros \\
\hline
Polinomial & $(\delta(\vect{x}_i\cdot\vect{x}_j)+\kappa)^d$ & $\delta$, $\kappa$, e $d$ \\
Gaussiano (ou RBF) & $\exp(-\sigma\norma{\vect{x}_i-\vect{x}_j}^2)$ & $\sigma$ \\
Sigmoidal & $\tanh(\delta(\vect{x}_i\cdot\vect{x}_j)+\kappa)$ & $\delta$ e $\kappa$ \\
\hline
\end{tabular}
\quadro{Funções de kernel comumente usadas}\label{quadro:kernels}
\end{table}

\subsubsection{Classificação multiclasses}\label{sec:svmmulti}

% hsu2002comparison

Como SVMs fazem classificação binária, é necessário o uso de alguma técnica para adaptar problemas de classificação multiclasses. As mais populares são um contra todos (\emph{one-against-all}) e um contra um (\emph{one-against-one}).

Na técnica um contra todos, é treinada uma SVM para cada classe contra todas as outra classes ao mesmo tempo. \citeonline{vapnik1998statistical} propôs uma extensão a esta técnica para utilizar os valores contínuos de cada SVM (ao invés do retornado por $\operatorname{sinal}$) e ordenar as classes descendentemente de acordo com o módulo da classificação de cada uma~\cite{abe2003analysis}.

Na técnica de classificação um contra um, ou também chamado de \emph{pairwise}, cada classe é treinada contra outra classe do problema; a classe selecionada é a que foi selecionada mais vezes nas classificações contra todas as outras classes. Isso resulta, em um problema de classificação de $n$ classes, em $n(n - 1)/2$ SVMs \cite{kressel1999pairwise}.

% TODO há mais técnicas interessantes (as baseadas em árvore de decisão e
% all-together), talvez apontar desempenho delas etc etc

%%\subsubsubsection{Complexidade computacional}
%% tratar

%%\subsubsubsection{Implementações}
% abandonada por falta de tempo, vamos citar apenas a libsvm na metodologia
% libsvm 
% PyML
% svm-light
% svm-perf

